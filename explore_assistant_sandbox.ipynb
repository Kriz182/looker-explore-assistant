{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2vlowVCC4LH"
      },
      "source": [
        "# Explore Assistant\n",
        "This document provides instructions on how to install and customize the Explore Assistant demo. The demo is a web application that allows users to explore data in Looker by asking questions in natural language.\n",
        "\n",
        "DISCLAIMER : DO NOT INTENDED TO BE USED IN A PRODUCTION ENVIRONMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqNHMAkkCbwa"
      },
      "outputs": [],
      "source": [
        "# @title Setup : Installing Required Librairies\n",
        "# If you're running this code locally, make sure you to install all librairies\n",
        "\n",
        "!pip install google-cloud-aiplatform --upgrade --user\n",
        "!pip install pandas\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3eVa448EmSb"
      },
      "outputs": [],
      "source": [
        "# @title Restarting the Colab\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1DpiR1VETP9"
      },
      "source": [
        "### Authenticating your notebook to GCP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_kXw0EIDkd3"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-lVxwmtEywE"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2cmKCMhFh2c"
      },
      "source": [
        "Update Project and Region of your Vertex AI Project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVaXeHqHE3Zk"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from vertexai.language_models import TextGenerationModel\n",
        "\n",
        "PROJECT_ID = \"project\"  # @param {type:\"string\"}\n",
        "LOCATION = \"region\" # @param {type:\"string\"}\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPe3ozloE9Er",
        "outputId": "70f9eedc-7771-40b9-bef9-911608f5254c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradio version: 4.12.0\n",
            "Vertex AI SDK version: 1.38.1\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import aiplatform\n",
        "import gradio as gr\n",
        "import urllib.parse\n",
        "import json\n",
        "\n",
        "# Print LangChain and Vertex AI versions\n",
        "print(f\"Gradio version: {gr.__version__}\")\n",
        "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AevRra6IHJWe"
      },
      "source": [
        "### Initiating Vertex AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyHoBkETHMNO"
      },
      "outputs": [],
      "source": [
        "# Definig parameters to be used.\n",
        "# You can modify it to be used with text-bison-32k for large models.\n",
        "# Gemini Pro is also available : https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/sdk-for-gemini/gemini-sdk-overview#load_a_gemini_model\n",
        "parameters = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 140,\n",
        "    \"top_p\": 0.8,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbqL9PfqIv9X"
      },
      "source": [
        "### Looker's Semantic Context and Examples\n",
        "Paste you **Model-Context** and **Examples** here\n",
        "\n",
        "Update the **base url to your instance**\n",
        "Using the semantic layer as context for the LLM to extract the relevant field to build the query.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Em7BbvhIWQ6"
      },
      "outputs": [],
      "source": [
        "# Default Base for Embedding the demo\n",
        "looker_base_url = \"https://ceworkshops.cloud.looker.com/embed/explore/thelookai/order_items?\"\n",
        "\n",
        "# Semantic Model Context : Result of the first Colab\n",
        "context = \"\"\"You\\'re a developer who would transalate questions to a structured URL query based on the following dicitonnary - choose only the fileds in the below description\n",
        "\n",
        "---- Past you Model Context Here\n",
        "---- Paste your Examples here\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3-l-ByzJVrA"
      },
      "source": [
        "### Gradio's Functions\n",
        "Function that would be used later by Gradio interface in order to render the results from Looker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KA8ZV1u_JhA-"
      },
      "outputs": [],
      "source": [
        "# Savings Logs to further train the model.\n",
        "def save_logs(input_text, output_text, filename):\n",
        "    formatted_input_text = json.dumps(input_text)[1:-1]\n",
        "    formatted_output_text = json.dumps(output_text)[1:-1]\n",
        "\n",
        "    with open(filename, 'a') as file:\n",
        "        line = f'{{\"input_text\": \"{formatted_input_text}\", \"output_text\": \"{formatted_output_text}\"}}\\n'\n",
        "        file.write(line)\n",
        "\n",
        "    return True\n",
        "\n",
        "# Define a function to process the search query and return results\n",
        "def search(query):\n",
        "    # Formatting prompt\n",
        "    llm = \"\"\"\n",
        "    input: {}\n",
        "    output: \"\"\".format(query)\n",
        "    # Building the prompt\n",
        "    predict = context + llm\n",
        "    # Retrieving Results from Model\n",
        "    response =  model.predict(predict,**parameters).text\n",
        "    response = response.strip()\n",
        "    # Saving Logs\n",
        "    if save_logs(query, response, \"logs.jsonl\"):\n",
        "            #print(\"Logs Saved Correctly\")\n",
        "    # Percent Encoding\n",
        "    query_url = urllib.parse.quote(response, safe=':/?&=,[]{}')\n",
        "    # Building the Embedded URL\n",
        "    url = f\"{looker_base_url}{query_url}&toggle=dat,pik,vis&allow_login_screen=true\"\n",
        "    #print(url)\n",
        "    return f'<iframe src=\"{url}\" style=\"width:100%; height:600px;\"></iframe>'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PgF09TVJx6q"
      },
      "source": [
        "## Running the demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA6JyurEJ60h"
      },
      "outputs": [],
      "source": [
        "# Create the Gradio app with custom layout\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    # Explore Assistant\n",
        "\n",
        "    \"\"\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=10) :\n",
        "            search_input = gr.Textbox(label=\"Type your question and press Enter\", lines=1, placeholder=\"Sales this week ?\")\n",
        "    with gr.Row():\n",
        "        search_results = gr.HTML()\n",
        "        search_input.submit(search, inputs=search_input, outputs=search_results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENVhL21XOX5v"
      },
      "source": [
        "## Run this cell show the all the saved logs :\n",
        "Showing Logs Saved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8DDmCQW4ObqA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "f0f94e87-95f2-4d79-df87-fdbafa9f666e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'logs.jsonl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a5de6574a292>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Read the JSON Lines file and process each line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonl_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Load the line as a JSON object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'logs.jsonl'"
          ]
        }
      ],
      "source": [
        "# # U\n",
        "jsonl_file_path = 'logs.jsonl'\n",
        "\n",
        "# Read the JSON Lines file and process each line\n",
        "with open(jsonl_file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        # Load the line as a JSON object\n",
        "        json_data = json.loads(line)\n",
        "\n",
        "        # Extract the input and output strings\n",
        "        input_string = json_data.get('input_text', '')\n",
        "        output_string = json_data.get('output_text', '')\n",
        "\n",
        "        # Format and print the data\n",
        "        print(f'input: {input_string}')\n",
        "        print(f'output: {output_string}')\n",
        "        print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}